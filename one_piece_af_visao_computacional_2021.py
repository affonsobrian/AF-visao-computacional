# -*- coding: utf-8 -*-
"""One_Piece_AF_Visao_Computacional_2021.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VI-0nMIh2epzQ54XwsWKmXErHw-GBCq7
"""

import os
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras import regularizers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model, load_model, Sequential
from tensorflow.keras.optimizers import Adam, Adamax
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from PIL import Image
from IPython.core.display import display, HTML
import matplotlib.pyplot as plt

"""# Preparacao dos dados"""

!gdown https://drive.google.com/uc?id=1fyfRuFWmDYi_HSN0reL_YcA1Kj7vw1NS

!unzip "one piece.zip"

"""# Pre processing"""

def preprocess (random_seed = 1):
    path = '/content/Data'
    labels=[]    
    filepaths=[]
    classlist = os.listdir(path)

    for classe in classlist:
        classpath=os.path.join(path, classe)
        file_list = os.listdir(classpath)

        for file in file_list:
            filepaths.append(os.path.join(classpath, file))
            labels.append(classe)

    files_pd = pd.Series(filepaths, name='filepaths')
    labels_pd = pd.Series(labels, name='labels')
    df = pd.concat([files_pd, labels_pd], axis=1) 
    train_df, test_df = train_test_split(df, train_size=0.7, shuffle=True, random_state=random_seed, stratify=df['labels'])

    return train_df, test_df

train_df, test_df = preprocess()
# !ls /content/Data -a

train_df.head(5)

test_df.head(5)

img_size = (224,224)

def scalar(img):    
    return img

train_generator = ImageDataGenerator(preprocessing_function=scalar, horizontal_flip=True)
test_generator = ImageDataGenerator(preprocessing_function=scalar)

train_gen = train_generator.flow_from_dataframe( train_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',
                                    color_mode='rgb', shuffle=True, batch_size=32)

test_gen= test_generator.flow_from_dataframe( test_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',
                                    color_mode='rgb', shuffle=False, batch_size=32)

"""# Modelo"""

img_shape=(img_size[0], img_size[1], 3)
model_name='EfficientNetB3'
model = tf.keras.applications.EfficientNetB3(include_top=False, weights="imagenet", input_shape=img_shape, pooling='max') 
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

classes=list(train_gen.class_indices.keys())
class_count=len(classes)

model_name='EfficientNetB3'
base_model=tf.keras.applications.EfficientNetB3(include_top=False, weights="imagenet",input_shape=img_shape, pooling='max') 
x=base_model.output
x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)
x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),
                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)
x=Dropout(rate=.45, seed=123)(x)        

output=Dense(class_count, activation='softmax')(x)
model=Model(inputs=base_model.input, outputs=output)
model.compile(Adamax(learning_rate=.001), loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(x=train_gen,  epochs=15, verbose=1, initial_epoch=0)

"""# Avaliacao"""

loss, accuracy = model.evaluate(test_gen)
print(f'loss on test set = {loss}')
print(f'accuracy on test set = {accuracy}')

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

model.save('my_model.h5')

from keras.models import load_model

!gdown https://drive.google.com/uc?id=1aydMMdyJ-C_Mmgk-bWAHurwhBDJ8rXMN

model = load_model('my_model.h5')

img_path=r'Data/Luffy/1.jpg'
img=plt.imread(img_path)
print (img.shape)
plt.axis('off')
plt.imshow(img)
plt.show()

from tensorflow.keras.preprocessing import image
img = image.load_img(img_path, target_size=(224, 224, 3))

x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
preds = model.predict(x)

from enum import Enum

class ClassNames(Enum):
  BROOK = 0
  CHOPPER = 1
  FRANKY = 2
  JINBEI = 3
  LUFFY = 4
  NAMI = 5
  ROBIN = 6
  SANJI = 7
  USOPP = 8
  ZORO = 9

classes = np.argmax(preds, axis = 1)
print('Success' if classes[0] == ClassNames.LUFFY.value else 'Failed')

